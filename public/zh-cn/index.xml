<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>我的AI奥德赛之旅</title>
    <link>http://localhost:1313/zh-cn/</link>
    <description>Jiezi&#39;s blog on AI with a focus on personalized LLM applications and AI Alignment.</description>
    <generator>Hugo 0.140.2 &amp; FixIt v0.3.16-f66dc32e</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 01 Jan 2025 07:42:33 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/zh-cn/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>OpenReview 深度分析（一）：基础概念与逻辑</title>
      <link>http://localhost:1313/zh-cn/posts/openreview-analysis-series-1/</link>
      <pubDate>Wed, 01 Jan 2025 07:42:33 +0000</pubDate><author>ai4fun2004@gmail.com (杰子)</author>
      <guid>http://localhost:1313/zh-cn/posts/openreview-analysis-series-1/</guid>
      <category domain="http://localhost:1313/zh-cn/categories/project/">Project</category>
      <description>&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/openreview_analysis/openreview_logo.png&#34; alt=&#34;/openreview_analysis/openreview_logo.png&#34; srcset=&#34;http://localhost:1313/openreview_analysis/openreview_logo.png?size=small, http://localhost:1313/openreview_analysis/openreview_logo.png?size=medium 1.5x, http://localhost:1313/openreview_analysis/openreview_logo.png?size=large 2x&#34; data-title=&#34;OpenReview Logo&#34; style=&#34;--width: 550px;--aspect-ratio: 550 / 108;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;&#xA;&lt;p&gt;AI及大模型领域的研究层出不穷。在有限的精力下，对大部分的新研究可以略读————粗通其义即可，但对于一些重要的研究则有必要精读，并对文献进行更批判性、更辩证的思考。恰好，&lt;a href=&#34;https://openreview.net/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Openreivew&lt;/a&gt;网站为文献精读提供了很好的辅助，尤其是它公开呈现了同行评议与论文作者抗辩的信息，从而可以让我们借助不同的视角，关注在此研究中同行聚焦的一些问题和挑战，以及围绕这些问题上作者的说明和思考。[1]&lt;/p&gt;&#xA;&lt;p&gt;本文的写作，是我作为AI学习者，试图将Openreview中的分析和讨论，整合到文献阅读和思考过程中去；同时作为个人开发者，我也希望将此过程工具化：即能够以底层数据交互的形式自动获取相关文献的评审与讨论，进而结合SemanticScholar等文献检索工具、Zotero等文献管理工具，实现在文献上的端到端的个人知识管理。此外，作为算法爱好者，我也将尝试理解和探索OpenReview背后的理念与机制，如它的开放性审议理念、审稿分配机制等。&lt;/p&gt;&#xA;&lt;p&gt;基于以上目的，本文将划分为三部分，其中第一部分将介绍OpenReview的基础概念与逻辑，并说明如何使用官方的API获取重要的数据；第二部分侧重于围绕OpenReview数据的系统化应用，并推介我封装后的OpenReview工具（开源），旨在实现端到端的知识管理；第三部分将分析OpenReview背后的理念与机制，并探讨平台重要的算法如“文章-评委”关联度评分（affinity score）、文章推荐/分配等涉及的机器学习、运筹学算法等。&lt;/p&gt;&#xA;&lt;h2 id=&#34;基本理念从开放文献到开放评议&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;基本理念：从开放文献到开放评议&lt;/span&gt;&#xA;  &lt;a href=&#34;#%e5%9f%ba%e6%9c%ac%e7%90%86%e5%bf%b5%e4%bb%8e%e5%bc%80%e6%94%be%e6%96%87%e7%8c%ae%e5%88%b0%e5%bc%80%e6%94%be%e8%af%84%e8%ae%ae&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;即便在费用承担上等问题上仍有争议，但开放文献（open access）普遍被认为有助于促进知识的共享及科研上的交流与协作。如预印网站&lt;a href=&#34;https://arxiv.org/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Arxiv&lt;/a&gt;有效支持了如AI、生物医疗等快速发展和更新的研究领域，备受科研者和学习者的青睐。&lt;/p&gt;&#xA;&lt;p&gt;既然文献可以开放，那么关于文献的评审信息（Peer Review）是否应当开放？这些信息应当对谁开放（to whom）？什么时候开放（when）？多大程度上开放（what）？这是OpenReivew.org尝试回答的问题。OpenReivew秉持的基本理念是：首先，文献的传播与文献的评估/审议应当相分离，这样无需等待漫长的审稿读者就可以及时找到最新的研究；其次，OpenReivew将开放的选择权（who / when / what）交给期刊、会议的组织方，并从平台和工具层面有力的支持评审信息的开放。[2]&lt;/p&gt;&#xA;&lt;p&gt;在我看来，OpenReview的主要特色有：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;一是它的开放性。它开放面向各种组织（如会议、期刊，乃至学期作业等）在平台上设置venue，完成评审决议过程；同时它也支持提交文章和评审信息的开放，并将选择权交给组织方。&lt;/li&gt;&#xA;&lt;li&gt;二是它的高效和专业性。一方面，平台聚拢了一批各领域上的专业人士与研究者；另一方面，平台开发了一系列的推荐机制和算法，支持将待审议的论文推荐给对应领域的研究者（作为评委），以实现有质量的、高效的同行审议。 &lt;br&gt;&#xA;关于具体的机制和算法，我将在“OpenReview 深度分析（三）：机制与算法”中做更详细的讨论。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;除了以上对组织方的支持，OpenReview对论文作者和学习者的价值还包括：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;从论文作者的角度，以OpenReview作为平台可以更好的管理论文投递、与审稿人的意见交互、修订完善与抗辩等工作；&lt;/li&gt;&#xA;&lt;li&gt;对于论文阅读者而言，关于AI领域的一些重要会议，OpenReview平台上的论文及同行评议数据完全开放，无疑是借助不同视角更深入理解文献的利器；&lt;/li&gt;&#xA;&lt;li&gt;此外，OpenReivew平台提供的工具也全部开源，意味着底层可以借助其数据、API/SDK等做进一步的开发和连接，以更便利的使用OpenReview上的资源和数据。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;重要概念与代码building-blocks&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;重要概念与代码building blocks&lt;/span&gt;&#xA;  &lt;a href=&#34;#%e9%87%8d%e8%a6%81%e6%a6%82%e5%bf%b5%e4%b8%8e%e4%bb%a3%e7%a0%81building-blocks&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;基础流程图&lt;/strong&gt;&#xA;在发起活动、征收论文和评议流程上，OpenReview提供的支持如下图所示：&#xA;&lt;figure&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/openreview_analysis/openreview_process_flow.png&#34; alt=&#34;OpenReview的工作流与论文评审过程一致，在各个环节上提供了工具支持。&#34; srcset=&#34;http://localhost:1313/openreview_analysis/openreview_process_flow.png?size=small, http://localhost:1313/openreview_analysis/openreview_process_flow.png?size=medium 1.5x, http://localhost:1313/openreview_analysis/openreview_process_flow.png?size=large 2x&#34; data-title=&#34;OpenReview Workflow&#34; style=&#34;--width: 1646px;--aspect-ratio: 1646 / 614;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;figcaption class=&#34;image-caption&#34;&gt;OpenReview的工作流与论文评审过程一致，在各个环节上提供了工具支持。&lt;/figcaption&gt;&#xA;  &lt;/figure&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;发起：组织方在OpenReview上注册并发起活动，设置关键时间节点，招募相关人员（如领域主席、评委等 ）；&lt;/li&gt;&#xA;&lt;li&gt;提交：论文作者提交论文并登记信息。论文提交后，组织方可借助OpenReview提供的工具，评估论文与评委的相关度（affinity score），并进一步将论文推荐/分配给不同的评委；同时，OpenReview也支持评委在无利益冲突的情况下申请评审某论文（bidding）。&lt;/li&gt;&#xA;&lt;li&gt;评审：和常规的评审流程一样，一般是多位评委独立对论文打分，并给出评审意见；作者有机会抗辩并进一步解释说明；给定时间内多轮交互后，评委可修订最终打分，作者也可以根据评委意见进一步修订；组织方最后做关于文章的meta review。&#xA;评审决议独立于论文的传播，即组织方可决定论文在提交后即开放，而不是等到评审决议后再开放。&lt;/li&gt;&#xA;&lt;li&gt;决议：评议环节结束后，领域主席给出最终评审意见，做最后的刊印前修订。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;参考&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;参考&lt;/span&gt;&#xA;  &lt;a href=&#34;#%e5%8f%82%e8%80%83&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;[1] OpenReview官方帮助文档参见: &lt;a href=&#34;https://docs.openreview.net/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://docs.openreview.net/&lt;/a&gt;。关于OpenReivew的简要说明可参见：https://openreview.net/about。&#xA;[2] OpenReivew肇始于2013年ICML的一个Peer Reviewing and Publishing Models的工作会议上，同时它作为平台也支持了ICML会议的评审过程。 关于OpenReivew的理念，以及OpenReview支持此次会议的实证研究结果可参见&lt;a href=&#34;https://openreview.net/pdf?id=xf0zSBd2iufMg&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;此文章&lt;/a&gt;，相关的讨论进一步&lt;a href=&#34;https://openreview.net/forum?id=xf0zSBd2iufMg&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;参见此处&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>从文献速读到批判性阅读</title>
      <link>http://localhost:1313/zh-cn/posts/paper-critic-series-1/</link>
      <pubDate>Tue, 24 Dec 2024 07:42:33 +0000</pubDate><author>ai4fun2004@gmail.com (杰子)</author>
      <guid>http://localhost:1313/zh-cn/posts/paper-critic-series-1/</guid>
      <category domain="http://localhost:1313/zh-cn/categories/project/">Project</category>
      <description>&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/paper_critics_series/lots-of-readings.png&#34; alt=&#34;/paper_critics_series/lots-of-readings.png&#34; srcset=&#34;http://localhost:1313/paper_critics_series/lots-of-readings.png?size=small, http://localhost:1313/paper_critics_series/lots-of-readings.png?size=medium 1.5x, http://localhost:1313/paper_critics_series/lots-of-readings.png?size=large 2x&#34; data-title=&#34;Lots of Readings&#34; style=&#34;--width: 1362px;--aspect-ratio: 1362 / 606;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;&#xA;&lt;p&gt;读书时，我导经常说起他读博时，最令人闻风丧胆的是博一考试——即所谓资格考，称称斤两，判断你是不是做研究的那块料。形式倒也简单，首先给出相关领域的文献列表，里面的文献大多是该领域的重要研究、关键发展，正是相关专业的主攻方向，甚至可能是学校里某位大佬的作品；然后每个学生认领一篇，为期一周准备，最终向评委会汇报答辩。&lt;/p&gt;&#xA;&lt;p&gt;看着简单吧？可汇报时，评委会大佬云集，运气好点/不好点，文献的作者也在场，大家围绕文献和相关研究，批评指摘，且问出一堆刁钻古怪的问题，极容易挂在台上。得，大侠您重新来过，或者科研不适合，您还是换条路吧。这么一来，搞得学生们特别紧张。一周时间里，只看这篇文献肯定不够，你得理解这个研究主题吧，那该文献研究领域的基础理论、发展脉络、最新进展你得了然于胸不是？既然是重要文献，那么这篇文献前前后后引用的和被引的文献你得有所了解吧？大佬们好指摘，那你也得展现出批判性思考吧，关于文献的优劣、启发、意义你得说出个子丑寅卯来吧？更不用说关于这篇文献的一些具体实现和细节，如方法论、实验设计、结果评估、复现与推广等，延展开来哪个不是一大堆的活儿？&lt;/p&gt;&#xA;&lt;p&gt;虽然让人难以招架，但这种old school的训练确实对于深度阅读和理解还是有很大帮助的。AI研究日新月异，如今有许多“文献快报”、“文献速读”的工具，方便我们快速了解最新的进展和应用；另一方面，对重要文献“慢读”、“精读”、“细读”的支持性工具却并不多见，而毋庸置疑，对关键文献的研读，恰能起到提纲挈领、举一反三的作用。因此，我想打造一款Paper Critic的AI工具，以支持科研工作者对文献的深入批判性阅读。&lt;/p&gt;&#xA;&lt;h2 id=&#34;驱动案例关于tot的批判性阅读&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;驱动案例：关于ToT的批判性阅读&lt;/span&gt;&#xA;  &lt;a href=&#34;#%e9%a9%b1%e5%8a%a8%e6%a1%88%e4%be%8b%e5%85%b3%e4%ba%8etot%e7%9a%84%e6%89%b9%e5%88%a4%e6%80%a7%e9%98%85%e8%af%bb&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;以“&lt;a href=&#34;https://arxiv.org/abs/2305.10601&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Tree of Thoughts: Deliberate Problem Solving with Large Language Models&lt;/a&gt;”为例，1 年半内该文献引用量已达1000+，文献动机和逻辑清晰，数据结果漂亮，也是我很喜欢的一个研究。它沿袭了大模型推理领域奠基之作Chain-of-Thought的思路，基于prompting方法，将大模型在复杂任务上的推理过程扩展为思路拆解、采样、评估的树状搜索模式，后续的研究也大多采用了类似的框架，可谓承上启下。总之，这是一篇优秀的研究，但我们不妨吹毛求疵一些，看看通过哪些渠道和方式，可以更深入的洞察和深挖这篇文章。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;既然这篇文献研究的是大模型推理（LLM Reasoning），属于prompting一脉，那么与之最为直接相关的CoT、Self-CoT / Auto-CoT、Graph-of-Thought等XoT系列的对比来看，本文在算法上的异同，研究的定位、价值是什么？针对以上问题，可以阅读引用与被引文献来辅助理解。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;聚焦在算法上，ToT将大模型推理过程转换为一个蒙特卡罗树搜索（Monte Carlo Tree Search）的过程，这种思路也是引导大模型推理的主流思路，不论是prompting方式引导，或是生成语料直接训练/微调。在此过程中，如何提高大模型作为样本生成者、样本评估者的能力？确保大模型生成和评估的有效性（effectiveness）和有效率（efficiency），这其中可能涉及生成环节的奖励函数/寻优函数的设计和学习、评估环节的LLM-as-Judge等主题。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;从实验来看，ToT一文显示算法在实验上取得了显著提升，且文章提供了Game of 24、creative writing、mini crossword等不同类型的实验，覆盖了数值分析、写作等领域。但如果更苛求一些，可以挑战的问题有：算法在不同场景上是否还有赖于人的设计与适配（framing）？在 24 点游戏和mini crossword上表现出来的显著提升，是来自于MCTS式的采样还是来自于大模型内在的思考？如果进一步扩展到略复杂的任务上，是否仍然能够有较优表现？如果前两者（ToT算法适配有赖于人工设计、扩展到复杂任务上表现下滑）为真，那么它和传统检索算法实际的优势和区别在哪里？在这些问题上，&lt;a href=&#34;https://medium.com/@konstantine_45825/llm-prompting-and-classical-ai-budding-romance-or-a-tango-with-two-left-feet-bc7e3800facd&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Konstantine Arkoudas写了一篇绝佳的博文分析&lt;/a&gt;，无疑可以用于参考。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;了解到这篇文章被NeurIPS 2023录用，那么可以进一步检索文章的同行评议信息，参照评议中的challenges和作者的rebuttal，可以对文章的一些关键难点有更深入的理解。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;当然，如果进一步扩展的话，可以考虑以下素材和内容：如大模型推理的另一脉，即随着OpenAI O1而大火的基于预训练、微调而提升大模型推理能力的相关研究，如Let&amp;rsquo;s verify step-by-step乃至近期的Coconut(Chain of Continuous Thought)都可以做了解；如关于大模型推理的成本与收益之争，以及推理中的inference scaling law；乃至更深一层的，大模型能够思考与不能思考，它只是在模仿语料中的类似推理分析的结构和步骤，还是真的“涌现”出的内在的逻辑与思考机制？&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;批判性来源&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;批判性来源&lt;/span&gt;&#xA;  &lt;a href=&#34;#%e6%89%b9%e5%88%a4%e6%80%a7%e6%9d%a5%e6%ba%90&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;参照以上人工进行批判性阅读和分析的思路机理，如果我们希望AI来辅助这一过程，则应当具备以下条件：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;语料。我认可“在同样语料下，同等尺寸的大模型能力趋于收敛”这一观点。在批判性阅读和分析上，丰富而充分的语料起决定性的作用。就AI研究领域而言，一些可供使用和探索的语料包括：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;文献库，如Arxiv、SemanticScholar、Google Scholar等，可用于检索、阅读论文和论文的关联文献，理解主题沿袭与对照分析。Connected Papers和Litmaps可以辅助快速定位相关的重要文献。&lt;/li&gt;&#xA;&lt;li&gt;同行评议数据如OpenReview，虽然网上不断有置疑部分评委的专业度，但如此公开的评审意见、作者反馈，这样第一手的讨论与交流信息非常难得，可以提供很多分析的视角。不过可惜的是，目前OpenReview支持的仅有部分会议论文。Alphaxiv提供了很棒的围绕论文读者和作者交互的途径，可惜上线不久，同样可惜数据不多。&lt;/li&gt;&#xA;&lt;li&gt;写作平台如Medium.com或一些博客上，经常会有关于特定论文的深入分析与探讨；一些社交媒体如reddit.com、twitter.com、hackernews.com等上，围绕一些有影响力的工作，也往往会有讨论和交流。上述两种类型信息较为繁芜，常常有很多基础性的介绍、推广、说明等，但也不乏深刻的洞见与观点。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;引导与分析过程。大模型具备了通识能力，缺乏目标指向性；prompting引导大模型聚焦（同样也是一种attention），以追求其能力上限。prompting也是一个炼丹的过程，可以考虑以下几种形态：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;给定任务和要求，但不做强提示与说明，主要依赖大模型自身的能力来完成批判性分析的过程。&lt;/li&gt;&#xA;&lt;li&gt;将引导与分析设计为一个大模型推理和思考的过程，通过chain-of-thought、tree-of-thought、divide-and-conquer等思路，策略性的引导大模型每次聚焦一个子主题，逐步完成阅读与分析过程。&lt;/li&gt;&#xA;&lt;li&gt;使用agent重构“检索-阅读-分析-评估”流程，将检索、RAG等工具化，由大模型来组织和串联端到端的阅读与分析、总结过程。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;理解与分析能力。这里考验的是大模型的基础能力，涉及任务可以拆解为：a.需要大模型基本的文本处理、文本理解与总结归纳；b. 需要大模型更专业的分析与反思。作为学术写作，要严格避免大模型的幻觉，或说车轱辘话的情况。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;调研与分析&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;调研与分析&lt;/span&gt;&#xA;  &lt;a href=&#34;#%e8%b0%83%e7%a0%94%e4%b8%8e%e5%88%86%e6%9e%90&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;为了避免重复造轮子，有必要对市面上的相似与相关产品做个简单的调研分析。&lt;/p&gt;&#xA;&lt;h3 id=&#34;文献阅读类&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;文献阅读类&lt;/span&gt;&#xA;  &lt;a href=&#34;#%e6%96%87%e7%8c%ae%e9%98%85%e8%af%bb%e7%b1%bb&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h3&gt;&lt;h3 id=&#34;文献评论类&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;文献评论类&lt;/span&gt;&#xA;  &lt;a href=&#34;#%e6%96%87%e7%8c%ae%e8%af%84%e8%ae%ba%e7%b1%bb&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h3&gt;&lt;h3 id=&#34;检索综述类&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;检索综述类&lt;/span&gt;&#xA;  &lt;a href=&#34;#%e6%a3%80%e7%b4%a2%e7%bb%bc%e8%bf%b0%e7%b1%bb&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h3&gt;&lt;h2 id=&#34;框架与结构&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;框架与结构&lt;/span&gt;&#xA;  &lt;a href=&#34;#%e6%a1%86%e6%9e%b6%e4%b8%8e%e7%bb%93%e6%9e%84&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;至此，Paper Critic这一AI辅助文献批判性阅读的框架与结构就呼之欲出了。&lt;/p&gt;&#xA;</description>
    </item>
    <item>
      <title>我的“拥抱开源”第一课（上）</title>
      <link>http://localhost:1313/zh-cn/posts/opensource-abcs-to-developers/</link>
      <pubDate>Tue, 24 Dec 2024 07:42:33 +0000</pubDate><author>ai4fun2004@gmail.com (杰子)</author>
      <guid>http://localhost:1313/zh-cn/posts/opensource-abcs-to-developers/</guid>
      <category domain="http://localhost:1313/zh-cn/categories/analysis/">Analysis</category>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;杰子注：本文为个人学习开源系列第一篇，主要聚集在开源的意义、开源的理念沿革、开源协议等方面。未来还将进一步探讨开源的协作方式与工作、开源生态、个人开发者的最佳实践等话题。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;相信许多朋友和我一样，作为使用者，少不得要学习参照Github等一些平台上的开源代码；作为开发者，一些项目工作也会直接或间接的开放给他人、贡献到开源社区。那么开源究竟指的是什么？参与开源意味着什么？其中又有哪些游戏规则需要遵守？&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/opensource_abcs/open-source-word-cloud.png&#34; alt=&#34;/opensource_abcs/open-source-word-cloud.png&#34; srcset=&#34;http://localhost:1313/opensource_abcs/open-source-word-cloud.png?size=small, http://localhost:1313/opensource_abcs/open-source-word-cloud.png?size=medium 1.5x, http://localhost:1313/opensource_abcs/open-source-word-cloud.png?size=large 2x&#34; data-title=&#34;OpenSource Words Cloud&#34; style=&#34;--width: 1019px;--aspect-ratio: 1019 / 519;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;&#xA;&lt;p&gt;现下许多公司或个人声称要坚定的”&lt;strong&gt;拥抱开源&lt;/strong&gt;“，可以上问题又往往是我们的盲区，由此引发不少争议来，如：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;不久前，&lt;a href=&#34;https://www.huxiu.com/article/3705273.html&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;某科技博主在视频（一则创意动画）使用了Github 上的开源代码，却声称是自己开发，且删除了开源代码的来源信息&lt;/a&gt;，为何会因此受到指责？&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/494108102/answer/2186825405&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;阿里巴巴在某开源产品的推广活动中，要求活动参加者在GitHub上刷star以获得礼品&lt;/a&gt;，为何这是不对的？&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/466111598/answers/updated&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;华为 Linux 内核贡献者提交大量的小修订&lt;/a&gt;，为何会被质疑低价值和刷KPI？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;本文正是我学习和理解开源的一个过程。我将立足在个人开发者这一角色上，围绕开源的理念、开源的规则、参与开源的最佳实践等方面，查询资料并探讨展开。关于本文中的一些信息和观点，我将尽量提供出处（如源自他处），如果读者有兴趣加深了解，建议参阅“进一步阅读”中的信息。&lt;/p&gt;&#xA;&lt;h2 id=&#34;拥抱开源更好的从大教堂走向集市&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;拥抱开源：更好的从大教堂走向集市&lt;/span&gt;&#xA;  &lt;a href=&#34;#%e6%8b%a5%e6%8a%b1%e5%bc%80%e6%ba%90%e6%9b%b4%e5%a5%bd%e7%9a%84%e4%bb%8e%e5%a4%a7%e6%95%99%e5%a0%82%e8%b5%b0%e5%90%91%e9%9b%86%e5%b8%82&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;想像以下两种产品和服务的生产形态：&lt;sup&gt;[1]&lt;/sup&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;一种是大教堂式的，这是一个精心设计、严密执行的过程，&lt;code&gt;建造一座教堂般，由个别的高手或一小群专家在光辉的孤立中小心翼翼地精雕细琢，时机未到之前，不会发布测试版。&lt;/code&gt;每个人只需要各司其职，完成属于自己的那一部分工作即可。管理自上而下单点化，无效的沟通最小化，跨边界的工作尽量被避免。&lt;/li&gt;&#xA;&lt;li&gt;另一种是集市式的，&lt;code&gt;一个有不同流程和不同方式的大市集，每个人服从着自由的规则&lt;/code&gt;。每个人都是执行者和决策者，沟通需要各种成员之间多点进行，组织围绕共同的愿景，通过知识的共享与知识的协作来推动任务的完成。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;figure&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/opensource_abcs/the-cathedral-and-the-bazaar.jpg&#34; alt=&#34;图一：大教堂与集市，图片来自https://mijowa.github.io/CatB/。此外，本章节中引用的内容也来自于《大教堂与集市》一书。&#34; srcset=&#34;http://localhost:1313/opensource_abcs/the-cathedral-and-the-bazaar.jpg?size=small, http://localhost:1313/opensource_abcs/the-cathedral-and-the-bazaar.jpg?size=medium 1.5x, http://localhost:1313/opensource_abcs/the-cathedral-and-the-bazaar.jpg?size=large 2x&#34; data-title=&#34;The Cathedral and the Bazaar&#34; style=&#34;--width: 827px;--aspect-ratio: 827 / 575;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;figcaption class=&#34;image-caption&#34;&gt;图一：大教堂与集市，图片来自https://mijowa.github.io/CatB/。此外，本章节中引用的内容也来自于《大教堂与集市》一书。&lt;/figcaption&gt;&#xA;  &lt;/figure&gt;&lt;/p&gt;&#xA;&lt;p&gt;管理学大师彼得-德鲁克指出，二十一世纪将涌现出越来越多的知识密集型的产品和服务，传统的“大教堂”式的自上而下、层级式的管理和沟通模式很难适用。他号召组织和管理形态的转型，并认为每一位知识工作者也应当是”有效的管理者“和决策者。&lt;/p&gt;&#xA;&lt;p&gt;然而，从”大教堂“转型到”集市“，并不意味着各种问题都能够迎刃而解。想想我们身边，许多人会为以下的事情困扰不已：项目或产品研发中，永远有开不完的会；关于功能与需求，迟迟难以达成共识；在参与成员之间的汇报、信息沟通和同步，总是耗去了大量的时间精力；计划之外的变动和执行中的差错，常常让项目的交付一拖再拖，等等。&lt;/p&gt;&#xA;&lt;p&gt;在以上例子中，虽然很多时候公司/组织在项目上未必是“大教堂”式，甚至有可能是采取了“集市“式自由与开放的模式，但由于缺少共同的理念，或更多是缺少有效的知识共享 / 知识协作的方式和工具，仍导致总体的低效率。在《人月神话》一书中，作者一针见血的指出，软件或项目研发中&lt;code&gt;“随着开发人员数目的增长，项目复杂度和沟通成本按人数的平方增加，而工作成果只会呈线性增长“&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;figure&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/opensource_abcs/two-types-of-organization_chart.jpg&#34; alt=&#34;图二：左为“大教堂”式自上而下的管理和沟通模式，右为“集市”式网络结构的管理和沟通模式。图片由Gemini生成。&#34; srcset=&#34;http://localhost:1313/opensource_abcs/two-types-of-organization_chart.jpg?size=small, http://localhost:1313/opensource_abcs/two-types-of-organization_chart.jpg?size=medium 1.5x, http://localhost:1313/opensource_abcs/two-types-of-organization_chart.jpg?size=large 2x&#34; data-title=&#34;Two Types of Organizations&#34; style=&#34;--width: 1879px;--aspect-ratio: 1879 / 939;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;figcaption class=&#34;image-caption&#34;&gt;图二：左为“大教堂”式自上而下的管理和沟通模式，右为“集市”式网络结构的管理和沟通模式。图片由Gemini生成。&lt;/figcaption&gt;&#xA;  &lt;/figure&gt;&lt;/p&gt;&#xA;&lt;p&gt;这是否意味着从大教堂到集市，“开放“与”高效“总是二律背反的？未必！开源就提供了一种很好的解法。开源就是一种“集市”式的知识共享和知识协作模式，它的理念最早从黑客文化中孕育而来，随着社区和人群的壮大，伴随并支持了重要项目、应用和基建的成功（如Linux等），并进一步反哺和推动了开源的协作方式和工具的发展和成熟，进而在此基础上更广泛的创造、应用及所产生的影响，这无一不证明了&lt;code&gt;&amp;quot;市集模式&amp;quot;是可行的，并且运作得很好，这个事实带来了相当的震憾&lt;/code&gt;。为什么？让我们一步一步来看。&lt;/p&gt;&#xA;&lt;h2 id=&#34;理念与源流从黑客文化到自由软件再到开源&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;理念与源流：从黑客文化到自由软件再到开源&lt;/span&gt;&#xA;  &lt;a href=&#34;#%e7%90%86%e5%bf%b5%e4%b8%8e%e6%ba%90%e6%b5%81%e4%bb%8e%e9%bb%91%e5%ae%a2%e6%96%87%e5%8c%96%e5%88%b0%e8%87%aa%e7%94%b1%e8%bd%af%e4%bb%b6%e5%86%8d%e5%88%b0%e5%bc%80%e6%ba%90&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;为了理解开源的基本理念，有必要追溯到早期的计算机爱好者和黑客文化，再经由上世纪 80、90 年代自由软件运动演进，才到90年代末期 逐渐最终形成关于开源意义和内涵的共识。&lt;/p&gt;&#xA;&lt;p&gt;关于黑客文化和早期计算机爱好者们的故事，可以参考《大教堂与集市》一书的“黑客简史”一章。理查德·斯托曼(Richard M.Stallman)，这位早期计算机黑客文化的倡导者，主导并深刻影响了自由软件、开源运动的人物，曾如是描述“黑客文化”：&#xA;&lt;code&gt;​“出于兴趣而解决某个难题，不管它有没有用，这就是黑客。​”根据理查德·斯托曼的说法，黑客行为必须包含三个特点：好玩、高智商、探索精神。&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;另一个版本出自于史蒂文·利维(StevenLevy)的著作《黑客：计算机革命的英雄》&lt;sup&gt;[2]&lt;/sup&gt;，在他的描述里，黑客文化包括了更多价值追求、社会影响上的意义：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;转引自《黑客与画家》一书&lt;sup&gt;[3]&lt;/sup&gt;：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;使用计算机以及所有有助于了解这个世界本质的事物都不应受到任何限制。任何事情都应该亲手尝试。&lt;/li&gt;&#xA;&lt;li&gt;所有信息应该都是自由的。&lt;/li&gt;&#xA;&lt;li&gt;不信任权威，提倡去中心化。&lt;/li&gt;&#xA;&lt;li&gt;判断一名黑客的水平应该看他的技术能力，而不是看他的学历、年龄或地位等其他标准。&lt;/li&gt;&#xA;&lt;li&gt;你可以用计算机创造美和艺术。&lt;/li&gt;&#xA;&lt;li&gt;计算机使生活更美好。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;计算机程序无疑是黑客兴趣和探索的结晶。围绕软件著作权和它应有的社会价值，在上世纪 70、80 年代计算机爱好者们逐渐形成了两种不同的认知：一派认为软件所有权需要充分保护，并结合付费授权等商业行为，以形成进一步创新的动力；另一派则认为软件的更大价值在于开放和共享，应当更公开的传播和授权。前者一般称之为专有软件派，后者则是自由软件派，代表人物之一正是前文提到的理查德·斯托曼（RMS），他大声疾呼软件应当&lt;code&gt;&amp;quot;free as freedom&amp;quot;&lt;/code&gt;，他所推广的自由软件应当是：&lt;sup&gt;[4]&lt;/sup&gt;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;授权以自由的使用&lt;/li&gt;&#xA;&lt;li&gt;源码开放，可以服务于个人自由的研究与修订&lt;/li&gt;&#xA;&lt;li&gt;基于此的自由再发布和构建对外开放应用&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;专有软件如微软件的Windows等无疑获得了巨大的商业上的成功，而自由软件中也催生出了像Linux、GNU这样的世界级产品，它对社会文化的影响则更为重大，正如英国IT作家Glyn Moody所说：“&lt;code&gt;自由软件不仅仅是关于软件代码的，它们也与自由、分享有关，与社会有关。它们与创造有关，与美有关。这些代码深处寄托着我们最美好的心愿以及对最丑恶的东西的反抗，它将和人们的恒心共久长。&lt;/code&gt;”&lt;sup&gt;[5]&lt;/sup&gt;&lt;/p&gt;&#xA;&lt;p&gt;自由软件与专有软件在理念上的对峙、处于自由软件精神内核之一的GPL协议（下一节我们会进一步讨论它）copyleft式授权、倡导者及社区的理想主义与极为鲜明的个性，带来的一个副作用，就是自由、开放、共享的理念常常在商业公司或组织中，在商业化的推广和应用上遇到阻力。而开源则采取了一种更温和、更务实的姿态，如Open Source Initiatives提供了一套开源的标准定义：&lt;sup&gt;[6]&lt;/sup&gt;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;自由再分发：许可证不得限制任何个人或团体销售或赠予软件的权利。&lt;/li&gt;&#xA;&lt;li&gt;源代码：必须提供源代码，并且允许以源代码形式分发。&lt;/li&gt;&#xA;&lt;li&gt;衍生作品：许可证必须允许修改和衍生作品，并且允许它们以相同的许可证分发。&lt;/li&gt;&#xA;&lt;li&gt;技术中立：许可证不得歧视任何个人或团体，或任何特定的领域。&lt;/li&gt;&#xA;&lt;li&gt;不得歧视个人或团体：许可证不得限制任何人的使用、修改或分发软件的权利。&lt;/li&gt;&#xA;&lt;li&gt;不得歧视特定领域：许可证不得限制软件用于某个特定的领域。&lt;/li&gt;&#xA;&lt;li&gt;许可证的分发：许可证本身不得限制其他软件的分发。&lt;/li&gt;&#xA;&lt;li&gt;许可证的格式：许可证不得以特定格式为条件。&lt;/li&gt;&#xA;&lt;li&gt;专利授权：许可证必须明确授予所有用户专利权，以防止专利诉讼。&lt;/li&gt;&#xA;&lt;li&gt;不得限制其他软件：许可证不得限制与该软件一同分发的其他软件。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;开源继承了自由软件的理念，很大程度上，自由软件可视为开源软件，反之亦然。二者核心的区别在于，自由软件将使用和再开发视为一种基本权利，并要求传播和沿续这种开放性，这对于将代码或软件视为公司机密的商业场景是一种极大的挑战；而开源主要侧重于源代码开放可得，以促进在此基础上的协作，强调有限制的自由，对后续应用的限制较少，对于商业和非商业场景都比较友好。&lt;/p&gt;&#xA;&lt;p&gt;&lt;figure&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/opensource_abcs/open-source-ideology.jpg&#34; alt=&#34;图三：开源与自由软件有很大交集，但开源的理念更务实，主要侧重开放基础上的协作，对后续应用限制较少，因此对商业场景更友好。&#34; srcset=&#34;http://localhost:1313/opensource_abcs/open-source-ideology.jpg?size=small, http://localhost:1313/opensource_abcs/open-source-ideology.jpg?size=medium 1.5x, http://localhost:1313/opensource_abcs/open-source-ideology.jpg?size=large 2x&#34; data-title=&#34;Hacker Culture -&amp;gt; Free Software -&amp;gt; Open Source&#34; style=&#34;--width: 2983px;--aspect-ratio: 2983 / 1375;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;figcaption class=&#34;image-caption&#34;&gt;图三：开源与自由软件有很大交集，但开源的理念更务实，主要侧重开放基础上的协作，对后续应用限制较少，因此对商业场景更友好。&lt;/figcaption&gt;&#xA;  &lt;/figure&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;共识版权许可证与开源协议&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;共识：版权、许可证与开源协议&lt;/span&gt;&#xA;  &lt;a href=&#34;#%e5%85%b1%e8%af%86%e7%89%88%e6%9d%83%e8%ae%b8%e5%8f%af%e8%af%81%e4%b8%8e%e5%bc%80%e6%ba%90%e5%8d%8f%e8%ae%ae&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;开源协议可视为支持开源背后的基本共识，旨在实现保护所有者版权和利益、鼓励创新、消弥潜在的争端的目的。本章节将首先介绍版权与许可证机制，再进一步分类说明主要的开源协议，最后简要探讨开源协议的选择问题。&lt;/p&gt;&#xA;&lt;p&gt;**版权（著作权）**是创作者对其创作作品的所有权，是对作品所关联的一系列使用、传播、修订等行为，及所产生的利益和权益的保障&lt;sup&gt;[7]&lt;/sup&gt;。版权强调的是所有权的归属，旨在保护创作者的权益，以鼓励创新。软件、代码作品也存在版权。&lt;/p&gt;&#xA;&lt;p&gt;注意到版权中隐含了一个“首次销售原则”（或称之为“权利穷竭原则”）：当产品从所有者转移到使用者（往往是通过销售），所有者对该产品后续销售的控制权即告耗尽。如你购买了一本正版书籍，你可以随意将其转卖给他人，而无需获得出版社或作者的同意&lt;sup&gt;[7]&lt;/sup&gt;。然而在软件领域，事情有些不同：由于代码非实质资产，它本身复制和传播成本极低，软件使用者可以很容易在违背所有者意愿的情况下将软件二次传播或二次销售，这种二次销售也往往直接有悖于所有者的权益。因此，在软件等各种数字类产品行业，&lt;strong&gt;许可证(license)机制&lt;/strong&gt;产生了，它有点类似于“使用（权）说明书”，旨在避免首次销售原则对所有者的不利影响，强调使用者只有产品的使用权，在没有所有权或所有者认可的情况下，不得再度销售该产品。&lt;/p&gt;&#xA;&lt;p&gt;显然，许可证机制是对所有者权益的补全。可事情往往有两面性，引入许可证机制后，软件产品的分享和传播受到了很大的限制，还可能进一步影响在这基础上的知识共享与知识协作。有基于此，自由软件/开源的倡导者、组织和社区制订了各种类型的开源协议，本质上它们也是一种许可证，希望在保护所有者权益的同时，支持更自由的分享与传播。&lt;/p&gt;&#xA;&lt;p&gt;Open Source Initiatives最重要的职责之一，就是维护各种开源协议，并使之标准化，并具备社会、法律约束力。关于各种开源协议的详细定义和说明，请务必参考&lt;sup&gt;[8]&lt;/sup&gt;。按照各类开源协议的特征，大概可以将它们划分为以下三类，以方便理解：&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Copyleft类型&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;这一类许可证从自由软件和著名的GNU项目而来，它秉持了自由软件的全部理念，认为软件&lt;em&gt;应当&lt;/em&gt;被自由都使用和传播，而且使用或基于此代码修订而进一步生成的软件产品，它们也&lt;em&gt;应当&lt;/em&gt;遵守自由软件的理念（即源码开放并允许自由的使用、传播、修订等）。无怪乎有人会将其称之为软件“共产主义”的理念。&lt;/p&gt;&#xA;&lt;p&gt;该类许可证下的GNU General Public License (GPL)是影响重大一种开源协议此协议，此协议要求源码开放，授权以自由的使用、传播、修订；所有者对使用者无保障或其他责任义务；二次开发和传播中要明确透出版权、许可证信息，且要求衍生产品沿用GPL协议。&lt;/p&gt;&#xA;&lt;p&gt;针对一些不适合开源的代码或文件，如私有的、核心的文件等，GNU Lesser General Public License (LGPL)支持将它们抽取和隔离出来，以库的形式链接到其他文件（如遵循GPL协议的文件），从而为一些商业场景下应用开源代码提供了可能性和灵活性。Mozilla Public License (MPL)沿用此思路，它支持在文件层面明确开源/闭源、copyleft的要求，在保持MPL许可文件的独立性条件下，可以将该协议的文件与专有代码或其他开源协议下的代码组合在一个项目中，并进行一系列的开发、应用和传播。Eclipse Public License (EPL) 为促进商业使用，同样支持弱copyleft模式，支持与其他协议的代码共同使用；并引入“二级许可证”，，以实现与其他协议的兼容；强化专利保护。&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;特性&lt;/th&gt;&#xA;          &lt;th&gt;GPL&lt;/th&gt;&#xA;          &lt;th&gt;LGPL&lt;/th&gt;&#xA;          &lt;th&gt;MPL&lt;/th&gt;&#xA;          &lt;th&gt;EPL&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Copyleft强度&lt;/td&gt;&#xA;          &lt;td&gt;强&lt;/td&gt;&#xA;          &lt;td&gt;弱&lt;/td&gt;&#xA;          &lt;td&gt;弱&lt;/td&gt;&#xA;          &lt;td&gt;弱&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;与非开源软件链接&lt;/td&gt;&#xA;          &lt;td&gt;受限制&lt;/td&gt;&#xA;          &lt;td&gt;允许（库隔离）&lt;/td&gt;&#xA;          &lt;td&gt;允许（文件隔离）&lt;/td&gt;&#xA;          &lt;td&gt;允许&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;二进制文件再授权&lt;/td&gt;&#xA;          &lt;td&gt;不允许&lt;/td&gt;&#xA;          &lt;td&gt;不允许&lt;/td&gt;&#xA;          &lt;td&gt;允许&lt;/td&gt;&#xA;          &lt;td&gt;允许&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;对贡献者的法律保护&lt;/td&gt;&#xA;          &lt;td&gt;无&lt;/td&gt;&#xA;          &lt;td&gt;无&lt;/td&gt;&#xA;          &lt;td&gt;无&lt;/td&gt;&#xA;          &lt;td&gt;有&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;专利报复&lt;/td&gt;&#xA;          &lt;td&gt;有&lt;/td&gt;&#xA;          &lt;td&gt;有&lt;/td&gt;&#xA;          &lt;td&gt;有&lt;/td&gt;&#xA;          &lt;td&gt;有&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;&lt;strong&gt;Permissive类型&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;不同于copyleft类型，该类开源协议并不限制使用代码修订、二次开发后的衍生产品同样遵循相应的开源协议，即不具备“传播性”，因此也被视为更宽松的开源协议，在商业应用场景中备受青睐。此外，该类协议也更为简洁和灵活，这也是它们被广泛使用的原因之一。&lt;/p&gt;&#xA;&lt;p&gt;首先是著名的、个人开发者中广泛使用的MIT License。除版权声明外，该协议没有太多的其它要求；它支持商业使用；该协议要求在使用、修订、传播中透出版权信息及附属的MIT协议。BSD License 同样是一种非常宽松的开源协议，主要区别在于，它要求不得使用版权所有者或贡献者的名字进行背书或推广衍生产品（除非事先得到书面许可）。Apache License 2.0加强并明确了专利保护的内容（原所有者对于代码衍生专利的权益），同时类似于BSD协议，它也对商标（如版权所有者或贡献者的名字等）的使用进行了限制。&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;特性&lt;/th&gt;&#xA;          &lt;th&gt;MIT 许可证&lt;/th&gt;&#xA;          &lt;th&gt;BSD 许可证&lt;/th&gt;&#xA;          &lt;th&gt;Apache 许可证 2.0&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;长度&lt;/td&gt;&#xA;          &lt;td&gt;最短&lt;/td&gt;&#xA;          &lt;td&gt;短&lt;/td&gt;&#xA;          &lt;td&gt;较长&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;专利授权&lt;/td&gt;&#xA;          &lt;td&gt;隐式&lt;/td&gt;&#xA;          &lt;td&gt;隐式&lt;/td&gt;&#xA;          &lt;td&gt;显式&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;专利报复&lt;/td&gt;&#xA;          &lt;td&gt;无&lt;/td&gt;&#xA;          &lt;td&gt;无&lt;/td&gt;&#xA;          &lt;td&gt;有&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;商标使用&lt;/td&gt;&#xA;          &lt;td&gt;未提及&lt;/td&gt;&#xA;          &lt;td&gt;未提及&lt;/td&gt;&#xA;          &lt;td&gt;禁止&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;声明要求&lt;/td&gt;&#xA;          &lt;td&gt;版权和许可声明&lt;/td&gt;&#xA;          &lt;td&gt;版权和许可声明&lt;/td&gt;&#xA;          &lt;td&gt;版权、许可声明和修改说明&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;&lt;strong&gt;其他类型&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;除以上主要的开源协议外，还有许多其他开源协议：如颇具赛博朋克风的Do What The Fxxk You Want To Public License (WTFPL)；如适用于知识共享领域的Creative Commons协议，适用于特定地区的欧洲联盟公共许可协议 (EUPL)；或上述协议的衍生、变种。在这里展开一下Creative Commons协议。它主要应用在写作、艺术等领域，主要关注知识共享中的署名 (BY)、商业/非商业性使用 (NC)、允许/禁止修订与演绎 (ND)、如修订是否限制相同方式共享 (SA)等问题。&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;协议&lt;/th&gt;&#xA;          &lt;th&gt;允许分享&lt;/th&gt;&#xA;          &lt;th&gt;允许修订&lt;/th&gt;&#xA;          &lt;th&gt;允许商业使用&lt;/th&gt;&#xA;          &lt;th&gt;署名要求&lt;/th&gt;&#xA;          &lt;th&gt;相同方式共享&lt;/th&gt;&#xA;          &lt;th&gt;说明&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;CC BY (署名)&lt;/td&gt;&#xA;          &lt;td&gt;是&lt;/td&gt;&#xA;          &lt;td&gt;是&lt;/td&gt;&#xA;          &lt;td&gt;是&lt;/td&gt;&#xA;          &lt;td&gt;必须&lt;/td&gt;&#xA;          &lt;td&gt;否&lt;/td&gt;&#xA;          &lt;td&gt;最宽松的许可，只要署名，就可以自由分享和修改作品，可用于商业目的。&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;CC BY-SA (署名-相同方式共享)&lt;/td&gt;&#xA;          &lt;td&gt;是&lt;/td&gt;&#xA;          &lt;td&gt;是&lt;/td&gt;&#xA;          &lt;td&gt;是&lt;/td&gt;&#xA;          &lt;td&gt;必须&lt;/td&gt;&#xA;          &lt;td&gt;必须&lt;/td&gt;&#xA;          &lt;td&gt;可以自由分享和修改作品，可用于商业目的，但必须署名，并且 &lt;strong&gt;演绎作品必须也采用相同的许可协议&lt;/strong&gt;。&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;CC BY-ND (署名-禁止演绎)&lt;/td&gt;&#xA;          &lt;td&gt;是&lt;/td&gt;&#xA;          &lt;td&gt;否&lt;/td&gt;&#xA;          &lt;td&gt;是&lt;/td&gt;&#xA;          &lt;td&gt;必须&lt;/td&gt;&#xA;          &lt;td&gt;不适用&lt;/td&gt;&#xA;          &lt;td&gt;可以自由分享作品，可用于商业目的，但必须署名，并且 &lt;strong&gt;不允许修改作品&lt;/strong&gt;。&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;CC BY-NC (署名-非商业性使用)&lt;/td&gt;&#xA;          &lt;td&gt;是&lt;/td&gt;&#xA;          &lt;td&gt;是&lt;/td&gt;&#xA;          &lt;td&gt;否&lt;/td&gt;&#xA;          &lt;td&gt;必须&lt;/td&gt;&#xA;          &lt;td&gt;否&lt;/td&gt;&#xA;          &lt;td&gt;可以自由分享和修改作品，但必须署名，并且 &lt;strong&gt;不允许将作品或其演绎作品用于商业目的&lt;/strong&gt;。&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;CC BY-NC-SA (署名-非商业性使用-相同方式共享)&lt;/td&gt;&#xA;          &lt;td&gt;是&lt;/td&gt;&#xA;          &lt;td&gt;是&lt;/td&gt;&#xA;          &lt;td&gt;否&lt;/td&gt;&#xA;          &lt;td&gt;必须&lt;/td&gt;&#xA;          &lt;td&gt;必须&lt;/td&gt;&#xA;          &lt;td&gt;可以自由分享和修改作品，但必须署名，&lt;strong&gt;不允许将作品或其演绎作品用于商业目的&lt;/strong&gt;，并且 &lt;strong&gt;演绎作品必须也采用相同的许可协议&lt;/strong&gt;。&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;CC BY-NC-ND (署名-非商业性使用-禁止演绎)&lt;/td&gt;&#xA;          &lt;td&gt;是&lt;/td&gt;&#xA;          &lt;td&gt;否&lt;/td&gt;&#xA;          &lt;td&gt;否&lt;/td&gt;&#xA;          &lt;td&gt;必须&lt;/td&gt;&#xA;          &lt;td&gt;不适用&lt;/td&gt;&#xA;          &lt;td&gt;可以自由分享作品，但必须署名，&lt;strong&gt;不允许将作品用于商业目的&lt;/strong&gt;，并且 &lt;strong&gt;不允许修改作品&lt;/strong&gt;。 这也是最严格的CC BY 协议。&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://innovationgraph.github.com/global-metrics/licenses#license-rankings&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Github上罗列了近年来不同开源协议的选用情况&lt;/a&gt;，可以看到开源协议各类繁多。开源协议选择上，主要可以考虑以下因素：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;是否需要商业化使用；&lt;/li&gt;&#xA;&lt;li&gt;是否隶属于某个社区或项目，需要遵从共同的协议约束；&lt;/li&gt;&#xA;&lt;li&gt;开放与有条件的开放之间的权衡；&lt;/li&gt;&#xA;&lt;li&gt;对copyleft和pemissive开源协议理念的认可度。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;具体操作上，以下资料有较详细的讨论，此处仅做索引之用：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;为了方便缺少相关专业知识的用户选择许可证，Github还给出了&lt;a href=&#34;https://choosealicense.com/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;choosealicense&lt;/a&gt;网站，用户可以根据自身需求，一步一步选择合适的协议。&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.ruanyifeng.com/blog/2011/05/how_to_choose_free_software_licenses.html&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;阮一峰博客上&lt;/a&gt;翻译了一个简明的选择路线图，如下所示：&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;figure&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/opensource_abcs/license-choice.png&#34; alt=&#34;图四：开源协议选择路线图，引用自阮一峰博客&#34; srcset=&#34;http://localhost:1313/opensource_abcs/license-choice.png?size=small, http://localhost:1313/opensource_abcs/license-choice.png?size=medium 1.5x, http://localhost:1313/opensource_abcs/license-choice.png?size=large 2x&#34; data-title=&#34;Open Source License Choice&#34; style=&#34;--width: 800px;--aspect-ratio: 800 / 500;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;figcaption class=&#34;image-caption&#34;&gt;图四：开源协议选择路线图，引用自阮一峰博客&lt;/figcaption&gt;&#xA;  &lt;/figure&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;进一步阅读&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;进一步阅读&lt;/span&gt;&#xA;  &lt;a href=&#34;#%e8%bf%9b%e4%b8%80%e6%ad%a5%e9%98%85%e8%af%bb&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;[1] 开源运动的倡导者Eric S. Raymond在《大教堂与集市》一书中给出了这两个绝佳的譬喻。这本书是对开源的社会学观察和思考，强烈推荐。“大教堂与集市“娓娓道来，在具象的例子中道破开源理念的核心和意义，令人醍醐灌顶。另外“黑客圈简史“一章追忆早年计算机兴趣小组与黑客文化的兴起，读起来有当年天涯神贴的感觉（话说笔者可能是最后一波使用Telnet登录BBS的活跃者了吧）；“开垦心智层“、”魔法锅“从礼物文化、价值实现、经济学等视角，探讨开源的社会动力学；“黑客的反击“和后记可视为一位黑客/开源开发者的自我修养了。每一位独立开发者应当人手一册的书，它的开源版本可以&lt;a href=&#34;http://www.catb.org/~esr/writings/cathedral-bazaar/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;参见此处&lt;/a&gt;。&lt;br&gt;&#xA;[2] 史蒂文·利维著《&lt;a href=&#34;https://book.douban.com/subject/6860890/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;黑客：计算机革命的英雄&lt;/a&gt;》(Hackers:Heroes of theComputer Revolution)一书我暂未阅读，标记一下，待阅读后补充。此处内容转引自《黑客与画家》一书。&lt;br&gt;&#xA;[3] Y Combinator创始人保罗·格雷厄姆《黑客与画家》一书是关于黑客文化的个人随笔集，不乏一些真知灼见，可花了太多篇章去讨论具体的个人经历、项目，乃至编程工具与语言选择等问题，虽然也有围绕这些主题展开的作者的思考、体悟，但总体在启发性上略逊。&lt;br&gt;&#xA;[4] 关于自由软件的介绍可参见&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E8%87%AA%E7%94%B1%E8%BD%AF%E4%BB%B6&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;维基中文百科&lt;/a&gt;，此处为个人总结。&lt;br&gt;&#xA;[5] 此处文字转引自&lt;a href=&#34;https://www.ruanyifeng.com/blog/2005/03/post_112.html&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;阮一峰博客&lt;/a&gt;。原书为《天才莱纳斯：Linux传奇》(Rebel Code: Inside Linux and the Open Source Revolution)，可惜现在已经绝版，暂时未能找到。 &lt;br&gt;&#xA;自由软件的倡导者理查德·斯托曼(RMS)是一个传奇的、极具个人魅力的人物，但他对个人理念的执著也常招致一些争议。知乎关于“&lt;a href=&#34;https://www.zhihu.com/question/624356031/answer/3232910752&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Richard Stallman 罹患癌症，对于开源界会有多大影响？&lt;/a&gt;&amp;ldquo;话题上，作者@fisheuler​ 做了很好的介绍，他所援引的&lt;a href=&#34;https://news.ycombinator.com/item?id=37699851&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;来自HackerNews上的讨论&lt;/a&gt;也很值得一读。另外，理查德·斯托曼的随笔集&amp;rdquo;&lt;a href=&#34;https://www.gnu.org/philosophy/fsfs/rms-essays.pdf&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Free Software, Free Society: Selected Essays&lt;/a&gt;&amp;ldquo;暂未阅读，标记一下。&lt;br&gt;&#xA;[6] 关于开源的定义可参见&lt;a href=&#34;https://opensource.org/osd&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Open Source Initiatives&lt;/a&gt;，该组织致力于推广开源文化，制定和维护开源标准与协议。此外，《大教堂与集市》一书中“黑客的反击”则提供了开源运动的发展策略与发展历程。&lt;br&gt;&#xA;[7] 关于版权（著作权）定义参见&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E8%91%97%E4%BD%9C%E6%AC%8A&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;维基百科&lt;/a&gt;。关于发行权一次耗尽原则可参见&lt;a href=&#34;https://en.wikipedia.org/wiki/First-sale_doctrine&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;维基百科&lt;/a&gt;。&#xA;[8] Open Source Initiatives 维护了&lt;a href=&#34;https://opensource.org/licenses&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;详细的许可证信息，在此可参见开源协议的详细内容&lt;/a&gt;。Github上所支持的&lt;a href=&#34;https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/licensing-a-repository#disclaimer&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;全部协议可参见此处&lt;/a&gt;。&lt;/p&gt;</description>
    </item>
    <item>
      <title>AMD, Yes but ...</title>
      <link>http://localhost:1313/zh-cn/posts/amd-gpu-analysis/</link>
      <pubDate>Fri, 29 Nov 2024 07:42:33 +0000</pubDate><author>ai4fun2004@gmail.com (杰子)</author>
      <guid>http://localhost:1313/zh-cn/posts/amd-gpu-analysis/</guid>
      <category domain="http://localhost:1313/zh-cn/categories/analysis/">Analysis</category>
      <description>&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/amd_gpu_analysis/amd_vs_nvidia.png&#34; alt=&#34;/amd_gpu_analysis/amd_vs_nvidia.png&#34; srcset=&#34;http://localhost:1313/amd_gpu_analysis/amd_vs_nvidia.png?size=small, http://localhost:1313/amd_gpu_analysis/amd_vs_nvidia.png?size=medium 1.5x, http://localhost:1313/amd_gpu_analysis/amd_vs_nvidia.png?size=large 2x&#34; data-title=&#34;AMD vs Nvidia&#34; style=&#34;--width: 1410px;--aspect-ratio: 1410 / 514;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;tldr&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;TL;DR&lt;/span&gt;&#xA;  &lt;a href=&#34;#tldr&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;对于个人AI用户，AMD消费级GPU性价比高，且随着ROCm生态的成熟，短期内值得考虑选用，尤其是应用在相对成熟、保持更新的框架（如pytorch）或模型（主流的Huggingface模型）及应用（如ollama等）上，配置与迁移成本小。但长远年来，AMD公司战略上更侧重企业级市场，且面临GPU硬件架构的调整，AMD GPU在消费级AI市场上仍有较多的不确定性。此外，ZLUDA、SCALE等第三方的兼容CUDA类的GPGPU框架表现出了良好的性能和适用性，同样值得关注。&lt;/p&gt;&#xA;&lt;h2 id=&#34;引子&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;引子&lt;/span&gt;&#xA;  &lt;a href=&#34;#%e5%bc%95%e5%ad%90&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;作为一名AI爱好者和不资深的游戏玩家，前段时间，趁电商促销我入手了AMD Radeon™ RX 7900 XT的显卡。本着物尽其用的原则，我还想尝试用它来做一些LLM相关的应用。于是我对**个人用户能不能用AMD GPU做AI计算？它相较于Nvidia GPU究竟差在哪里？**话题产生了兴趣，我希望探索和解答以下问题：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;为什么大家都会说AMD GPU&lt;code&gt;看上去很美&lt;/code&gt;，但又是&lt;code&gt;你买我推荐，我买我不买&lt;/code&gt;的态度？&lt;/li&gt;&#xA;&lt;li&gt;截止当前，AMD GPU及ROCm生态圈发展状况如何？能不能做Nvidia GPU的平替？&lt;/li&gt;&#xA;&lt;li&gt;考虑到技术栈和产品服务的连续性，有必要审视AMD GPU的发展方向和策略。结合各类信息与报道分析，选用AMD GPU是不是一个可以“战未来”且不那么“冒风险”的决定？&lt;/li&gt;&#xA;&lt;li&gt;再放宽视野，Nvidia GPU凭借软硬件实力一家独大，其它厂商（如国产的GPU们），还有什么“曲线救国”的应用解决方案？从AMD / Intel / 微软和其它市面上的开、闭源方案里可能有哪些启发？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;需要说明的是，本文将立足于个人AI应用开发者/爱好者的视角，分析中将更关注消费级的GPU而非专业级GPU（或GPU加速卡），更侧重不同GPU及生态对上层应用开发的影响，而非探讨底层基础硬件、架构、通信等的技术细节。文中除数据与材料外，将有一些个人的见解和判断；因为GPU及生态发展迅猛，未来我也将尝试回过头来对照，并进一步更新。&lt;/p&gt;&#xA;&lt;h2 id=&#34;amd-gpu只是看上去很美&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;AMD GPU：只是“看上去很美“？&lt;/span&gt;&#xA;  &lt;a href=&#34;#amd-gpu%e5%8f%aa%e6%98%af%e7%9c%8b%e4%b8%8a%e5%8e%bb%e5%be%88%e7%be%8e&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;开始之前，简单回顾一下GPU计算的原理。虽然GPU起初用于图形渲染，但由于它对大量并行任务的支持，和体现出来的高效性，使得GPU同样适用于大量的并行数据计算，而这也是一切当前AI计算的前提。GPU用于AI计算，其核心的能力有：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;数据计算能力&lt;/li&gt;&#xA;&lt;li&gt;任务分解与线程调度能力&lt;/li&gt;&#xA;&lt;li&gt;高速缓存，及内外部的IO通信能力&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;其实任何的并发式系统都少不了上述的核心能力。我们把这样的系统比做一个企业：数据计算能力代表每一个员工的个人能力和业务水平；任务分解与线程调度能力代表企业管理、资源调度优化的效率，能否将每个人调动组织起来，人尽其材，物尽其用；高速缓存，及内外部的IO通信能力则相当于在大批量、批次化、阶段化的运营与生产服务中，通过有效沟通、时间与空间上的调度，以尽量减少损耗和浪费。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;GPGPU&lt;/strong&gt;（General-Purpose computing on Graphics Processing Units）指的是在图形处理单元（GPU）上进行通用计算的技术。这种技术利用GPU的并行处理能力来加速非图形计算任务，广泛应用于科学计算、机器学习、图像处理等领域。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;以这块AMD RTX 7900为例，官网中它的一些计算相关参数如下：&#xA;&lt;figure&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/amd_gpu_analysis/7900xt_specifications.png&#34; alt=&#34;图一：AMD GPU指标参数并不逊色，性价比高。&#34; srcset=&#34;http://localhost:1313/amd_gpu_analysis/7900xt_specifications.png?size=small, http://localhost:1313/amd_gpu_analysis/7900xt_specifications.png?size=medium 1.5x, http://localhost:1313/amd_gpu_analysis/7900xt_specifications.png?size=large 2x&#34; data-title=&#34;AMD RTX 7900关键参数&#34; style=&#34;--width: 2086px;--aspect-ratio: 2086 / 1320;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;figcaption class=&#34;image-caption&#34;&gt;图一：AMD GPU指标参数并不逊色，性价比高。&lt;/figcaption&gt;&#xA;  &lt;/figure&gt;&lt;/p&gt;&#xA;&lt;p&gt;对照来看几个关键指标：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;数据计算能力&lt;/strong&gt;：它的全精度FP32 计算 TFLOPs是 52（对比Nvidia RTX 4090为 83)；在半精度FP16 / BF16计算TFLOPs是 103（对比Nvidia RTX 4090为 330）；在INT 8上的TOPs无官方信息，但有&lt;a href=&#34;https://coinpoet.com/ml/learn/gpu/amd-radeon-rx-7900-xt&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;报告&lt;/a&gt;称是103（对比Nvidia RTX 4090为 660）；AI Accelerator（类Tensor Core）数目为168个（对比Nvidia RTX 4090为 512）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;details admonition note open disabled&#34;&gt;&#xA;  &lt;div class=&#34;details-summary admonition-title&#34;&gt;&lt;i class=&#34;icon fa-fw fa-solid fa-pencil-alt&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;关于TFLOPS (Floating-point operations per second)&lt;/div&gt;&#xA;  &lt;div class=&#34;details-content&#34;&gt;&#xA;    &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Source from: &lt;a href=&#34;https://baike.baidu.com/item/TFLOPS/2440337&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;百度百科&lt;/a&gt;&#xA;TFLOPS，即TeraFLOPS，是一个衡量GPU浮点运算能力的单位。它表示GPU每秒可以执行的浮点运算次数，通常以十亿次（Tera）为单位。浮点运算是一种基本的数学运算，广泛应用于图形处理、科学计算、机器学习等领域。因此，TFLOPS是衡量GPU性能的重要指标之一。TFLOPS的值越高，意味着GPU的浮点运算能力越强，处理任务的速度也就越快。&lt;/p&gt;&lt;/div&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&lt;div class=&#34;details admonition note open disabled&#34;&gt;&#xA;  &lt;div class=&#34;details-summary admonition-title&#34;&gt;&lt;i class=&#34;icon fa-fw fa-solid fa-pencil-alt&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;对比FP32 TFLOPs、FP16 TFLOPs、INT8 TOPs指标&lt;/div&gt;&#xA;  &lt;div class=&#34;details-content&#34;&gt;&#xA;    &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;以上三个指标代表的都是GPU在不同精度下对数据的运算能力，将进一步影响GPU的训练或推理速度。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;FP32针对的是 32 位浮点计算，高精度常用于模型的训练中，以确保梯度、权重的有效更新（如避免梯度爆炸或梯度消失）；&lt;/li&gt;&#xA;&lt;li&gt;FP16精度较低，但计算开销小，更适合推理任务，也可用于一些混合精度的训练；&lt;/li&gt;&#xA;&lt;li&gt;INT8 牺牲了精度，以换取更高的效率，适用于推理任务，特别是量化后模型的推理上；&#xA;此外，由于Nvidia在硬件上（如Tensor Cores）和软件上（如优化指令、优化算子等）做了大量优化，因此在FP16和INT8的计算上，N卡相较有显著的优势。&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/div&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;高速缓存&lt;/strong&gt;：这块显卡有20G的显存（对比Nvidia RTX 4090为 24G），由于显存用于加载和存放模型相关的重要数据（如模型权重、批次的训练数据等），大显存可以支持更大的神经网络规模或训练数据。对于个人偏推理性的大模型应用而言，推荐显存&amp;gt;=16G。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;内外部IO通信能力&lt;/strong&gt;：显存带宽为800G/s（对比Nvidia RTX 4090为 1008G/s），可以较好的支持模型从显存中频繁的读写数据（注：正常情况下IO通信开销时间约占总训练时间的1/3）。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;在消费级的显卡里，考虑到N家的4090 / 4090D价格居高不下，3090怕矿，2080Ti 22G担心魔改风险，4060Ti 16G基础计算性能较弱，4070Ti Super和 4080 Ti 性价比稍差，16G的显存也差点意思。&lt;a href=&#34;https://www.topcpu.net/gpu-r/fp32-float-desktop&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;横向对照其它各张显卡&lt;/a&gt;，AMD的 RX 7900xtx和7900xt看起来是不错的选择了。可随便翻翻论坛或问答社区，在个人选用上，AMD GPU总处于“你买我推荐，我买我不买”的尴尬境地。为什么呢？这少不了要说一说GPU的生态支持问题了。&lt;/p&gt;&#xA;&lt;h2 id=&#34;rocm-vs-cuda-生态圈护城河在弥合但用户粘性仍在&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;ROCm vs CUDA 生态圈：“护城河”在弥合，但用户粘性仍在&lt;/span&gt;&#xA;  &lt;a href=&#34;#rocm-vs-cuda-%e7%94%9f%e6%80%81%e5%9c%88%e6%8a%a4%e5%9f%8e%e6%b2%b3%e5%9c%a8%e5%bc%a5%e5%90%88%e4%bd%86%e7%94%a8%e6%88%b7%e7%b2%98%e6%80%a7%e4%bb%8d%e5%9c%a8&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;先来看AI计算市场份额90% 以上、处于行业事实标准的Nvidia的CUDA生态。老黄布局多年CUDA（Compute Unified Device Architecture），是为了充分利用GPU进行大量并行数据计算的底层接口，即将上层的模型训练或推理程序，转换为底层计算单元的基础命令执行。而我们常说的CUDA生态则是在CUDA基础上包括了：操作系统支持、多种基础运算与算法的高效算子、机器学习/深度学习通用框架（如pytorch\ tensorflow等）支持、针对机器学习/深度学习的加速算子/包（如ONNX / Flash Attention / bitsandbytes）等，这些作为基础设施，直接决定了上层模型训练、推理，应用开发的可实现性、有效性和便捷性。因此，CUDA生态也常被视为Nvidia护城河之一。&lt;/p&gt;&#xA;&lt;p&gt;&lt;figure&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/amd_gpu_analysis/cuda_ecosys.png&#34; alt=&#34;图二：关于CUDA生态的一张老图&#34; srcset=&#34;http://localhost:1313/amd_gpu_analysis/cuda_ecosys.png?size=small, http://localhost:1313/amd_gpu_analysis/cuda_ecosys.png?size=medium 1.5x, http://localhost:1313/amd_gpu_analysis/cuda_ecosys.png?size=large 2x&#34; data-title=&#34;CUDA eco-system&#34; style=&#34;--width: 1211px;--aspect-ratio: 1211 / 585;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;figcaption class=&#34;image-caption&#34;&gt;图二：关于&lt;a href=&#34;https://blogs.nvidia.com/blog/what-is-cuda-2/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;CUDA生态的一张老图&lt;/a&gt;&lt;/figcaption&gt;&#xA;  &lt;/figure&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;figure&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/amd_gpu_analysis/cuda_components.png&#34; alt=&#34;图三：Nvidia官网上对于CUDA生态及相关工具的进一步分类呈现。&#34; srcset=&#34;http://localhost:1313/amd_gpu_analysis/cuda_components.png?size=small, http://localhost:1313/amd_gpu_analysis/cuda_components.png?size=medium 1.5x, http://localhost:1313/amd_gpu_analysis/cuda_components.png?size=large 2x&#34; data-title=&#34;CUDA components&#34; style=&#34;--width: 1770px;--aspect-ratio: 1770 / 964;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;figcaption class=&#34;image-caption&#34;&gt;图三：Nvidia官网上对于&lt;a href=&#34;https://developer.nvidia.com/tools-ecosystem&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;CUDA生态及相关工具&lt;/a&gt;的进一步分类呈现。&lt;/figcaption&gt;&#xA;  &lt;/figure&gt;&lt;/p&gt;&#xA;&lt;p&gt;相比于老黄在CUDA生态上的长远投入、精心布局（不得不赞叹其眼光和企业家精神），AMD在GPU生态上则是落后了不少。一来是AMD起步晚，早些年重心在CPU上，一度只能是勉力存活，后来又忙着在CPU上和Intel干架，收购ATI后技术整合，无遐他顾。二是AMD走得弯路多，如硬件架构上，早期走GCN（Graph Core Next），后来又代之以侧重游戏和消费市场的RDNA和侧重计算及企业市场的CDNA双路线，再到未来又要整合RDNA和CDNA为UDNA。每一代架构技术上的连续性和兼容性不足，甚至同一架构下不同代次的技术兼容也有问题；另如计算框架上，刚开始AMD使用OpenCL作为编程模型，后来才使用更对标CUDA的HIP（Heterogeneous-compute Interface for Portability）——毕竟CUDA已经成为事实上的标准——以方便开发者在ROCm生态上使用。&lt;/p&gt;&#xA;&lt;p&gt;不过，近几年来，随着AMD在CPU市场站稳脚步、主机市场占据绝对优势，AMD也愈发重视自家的GPU生态（亦即 ROCm生态建设），主要的一些举措包括：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;ROCm全面对标CUDA建设，力求无痛兼容CUDA；同时保持开源生态，以扩大用户和影响，从而更好的对抗Nvidia霸权。&lt;/li&gt;&#xA;&lt;li&gt;积极联合生态圈伙伴，如&lt;a href=&#34;https://www.amd.com/en/products/software/rocm.html&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;2022 年底成为Pytorch组织成员，从而得到Pytorch原生支持&lt;/a&gt;；2023年&lt;a href=&#34;https://huggingface.co/blog/huggingface-and-amd&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;加入Huggingface的硬件伙伴联盟&lt;/a&gt;，2023 年-2024 年间一些重要的算子（如ONXX、DeepSpeed、Triton等，近期又有Flash Attention、bitsandbytes等）和综合性的应用（如Ollama、vLLM等）陆续支持ROCm。要知道大量的模型训练人员和AI开发者并不会去关注底层的算子、底层的实现，大家只关注能不能跑 pytorch，能不能使用各种加速算子高效计算等，因此这些举措意义重大，使得ROCm具有真正的可用性和易用性。&lt;/li&gt;&#xA;&lt;li&gt;另一个并不显见但对于ROCm同样重要的举措是大力进军企业级GPU市场。毕竟有了用户，特别企业级的大用户，有了利润来源，在商业上才能有效拉动ROCm的有效迭代与提升。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;figure&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/amd_gpu_analysis/rocm_ecosys.png&#34; alt=&#34;图四：ROCm全面对标CUDA生态，AMD消费级和企业级GPU使用共同的ROCm。&#34; srcset=&#34;http://localhost:1313/amd_gpu_analysis/rocm_ecosys.png?size=small, http://localhost:1313/amd_gpu_analysis/rocm_ecosys.png?size=medium 1.5x, http://localhost:1313/amd_gpu_analysis/rocm_ecosys.png?size=large 2x&#34; data-title=&#34;ROCm生态&#34; style=&#34;--width: 1996px;--aspect-ratio: 1996 / 988;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;figcaption class=&#34;image-caption&#34;&gt;图四：&lt;a href=&#34;https://www.amd.com/content/dam/amd/en/documents/instinct-tech-docs/product-briefs/amd-rocm-6-brief.pdf&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;ROCm&lt;/a&gt;全面对标CUDA生态，AMD消费级和企业级GPU使用共同的ROCm。&lt;/figcaption&gt;&#xA;  &lt;/figure&gt;&lt;/p&gt;&#xA;&lt;p&gt;综上所述，就计算框架和生态上（CUDA vs ROCm），我们可以看到AMD终于走在了正轨上，特别是近几年ROCm的优化迭代、增加的对不同框架、不同算子的支持，令人眼前一亮。当然，ROCm还一些广为用户所诟病的地方，如一直以来对Windows用户支持不好；对老一些的显卡支持不好（i.e.系统架构差异大，连续性差，升级支持少）。从技术层面来看，考虑到当前AI的基础算法架构（如深度学习的算法框架，以transformer为代表的大模型结构和主要运算等）也都已经相对成熟和稳定，ROCm在逐步补齐短板，优化计算逻辑，完善各种算子，追赶和兼容CUDA并非难以逾越的障碍。在技术层面外，用户的使用习惯与粘性、新的技术迭代（非颠覆）与持续投入、战略上的选择等一系列因素还会左右这场CUDA与ROCm之争，可预见的将来，Nvidia仍然将保持其霸主地位，而 AMD最好的角色仍是作为市场中的跟随者和补充。&lt;/p&gt;&#xA;&lt;h2 id=&#34;消费级gpu前瞻与隐忧&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;消费级GPU：前瞻与隐忧&lt;/span&gt;&#xA;  &lt;a href=&#34;#%e6%b6%88%e8%b4%b9%e7%ba%a7gpu%e5%89%8d%e7%9e%bb%e4%b8%8e%e9%9a%90%e5%bf%a7&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;企业级市场的利好&lt;/strong&gt;&lt;br&gt;&#xA;天下苦老黄久矣！大的IT企业，自然不想见到Nvidia一家独大，拥有垄断定价权——自家AI应用还没赚钱，钱先跑进了老黄口袋这可行。因此本着risk polling的思路也希望采购别家的GPU。最理想的情况下，能高度可用，稳定切换，承载一部分的流量和服务；再次之，暂作为plan B，掌握和熟悉不同的 GPU架构和服务，以备不时之需；还不济的话，那就捏着别家的采购单，作为和老黄谈判的筹码。对于AMD而言，由于近几年在CPU市场上形势大好，有更多的余力在GPU市场上角逐。近一两年，AMD打磨出了不错的企业级GPU产品，如&lt;a href=&#34;https://www.amd.com/en/products/accelerators/instinct/mi300.html#tabs-b9862a3bb5-item-58ebcbef73-tab&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;旗舰的MI300&lt;/a&gt;，对照Nvidia家的H200，在规格和参数上高出了不少，而且还拿出了相当有诚意的价格，接连&lt;a href=&#34;https://www.amd.com/en/newsroom/press-releases/2023-11-15-amd-brings-new-ai-and-compute-capabilities-to-micr.html&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;拿下了微软&lt;/a&gt;、&lt;a href=&#34;https://www.datacenterdynamics.com/en/news/ibm-cloud-to-add-amd-instinct-mi300x-gpus-in-2025/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;IBM&lt;/a&gt;等企业的订单。因此，企业级GPU市场中，AMD是完全可争取一席之地，成为Nvidia的补充和一定程度的替代。&lt;/p&gt;&#xA;&lt;p&gt;&lt;figure&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/amd_gpu_analysis/mi300_comparison.png&#34; alt=&#34;图五：AMD在企业级GPU市场上的旗舰MI300大有一战之力，赢得了不少订单&#34; srcset=&#34;http://localhost:1313/amd_gpu_analysis/mi300_comparison.png?size=small, http://localhost:1313/amd_gpu_analysis/mi300_comparison.png?size=medium 1.5x, http://localhost:1313/amd_gpu_analysis/mi300_comparison.png?size=large 2x&#34; data-title=&#34;MI300性能对照&#34; style=&#34;--width: 1658px;--aspect-ratio: 1658 / 1144;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;figcaption class=&#34;image-caption&#34;&gt;图五：AMD在企业级GPU市场上的旗舰MI300大有一战之力，赢得了不少订单&lt;/figcaption&gt;&#xA;  &lt;/figure&gt;&lt;/p&gt;&#xA;&lt;p&gt;赢得一部分企业市场，无疑会进一步坚定AMD大力做好GPU的决心。特别是AMD也深知自家ROCm还差火候，&lt;a href=&#34;https://www.eetimes.com/rocm-is-amds-no-1-priority-exec-says/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;苏妈和AMD其他高管也多次声称“ROCm是第一优先级&lt;/a&gt;。由于AMD家的企业级GPU（INSTINCT系列加速卡）和消费级GPU（Radeon系列）是共用ROCm的，因此，这也会意味着未来AMD仍将致力于建设ROCm，以使得技术越来越成熟，生态越来越完成完善。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;2025年消费市场的战略调整&lt;/strong&gt;&lt;br&gt;&#xA;共用的ROCm的优化，对于消费级GPU当然是好事。可这件事的另一面是，企业市场优先，而企业市场与消费市场的能力需求并不完全一致：如企业市场看重的是大量卡集群的协同能力，这可能是千卡、万卡集群的大规模运算（想想Nvidia家的NVlink）；企业用户往往聚集在一些GPU生态工具、运算类型与算子的优化，而并不强调整个生态的全面性；同时企业用户对服务要求也更高。在资源有限的情况下，AMD将聚集于利润率高的企业级GPU市场，暂时不发展消费级市场，&lt;a href=&#34;https://www.tomshardware.com/pc-components/gpus/amd-rdna-4-coming-in-early-2025-set-to-deliver-ray-tracing-improvements-ai-capabilities&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;2025 年AMD将发布的RDNA 4架构的消费级GPU 8000系列，将专注于中低端型号&lt;/a&gt;，这也意味着很难期待AMD近期会有面向个人消费者的有竞争力的可用于AI计算的显卡面世。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;当然，另一个疑似的可能原因是，新架构下AMD高端系GPU的良品率、性能提升存在瓶颈，尚不适用生产和推广。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;另一个战略上的不确定因素是，苏妈对于CPU和GPU的结合有着异乎寻常的偏好。站在AMD立场上，这也许很合理：毕竟点了CPU和GPU两条科技树，要是能在二者结合的地方玩出点花来，求其上者是走出一条新的奠定未来基业的技术路线，得乎中者是看看能不能应对消费市场上的AI硬件需求。我并不理解相关内容，这一块似乎Apple更具优势。个人理解，战略上的不坚定和摇摆乃是兵家大忌。&lt;/p&gt;&#xA;&lt;p&gt;虽然AMD暂时放弃高端消费级显卡（往往也是个人AI应用的高性价比选择），只是短期的调整性战略。但这件事背后，确实折射出在生产厂商视角下，利润低的个人消费市场似乎是“食之无味”的鸡肋。在这一问题上，我觉得很有必要为“AI GPU“的个人消费者重新正名。一方面，中小组织和个人用户是重要的贡献者和共同演进者，这一点对于像ROCm这样开源的、追赶中的生态尤其重要；而企业用户的需求往往是聚焦的、差异性的、闭源。另一方面，未来AI军备竞赛节奏将逐渐从大企业为主的训练，转变到更广泛中小组织和个人用户参与的推理和应用上，后者市场潜力巨大，但何况这波AI浪潮上，我们也看到了不少从中小组织和个人用户演进为引领者的案例。几年前，OpenAI以极低的成本（免费？）拿到了Nvidia的GPU支持，这两年，每次老黄亲自配送给OpenAI最新型号的显卡，成了Nvidia显卡最好的广告之一。服务好今天的中小组织和个人用户，也许就是明天的大买家。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;从RDNA/CDNA到UDNA&lt;/strong&gt;&lt;br&gt;&#xA;前文提到AMD GPU走的是侧重游戏和消费市场的RDNA（包括Radeon Pro / Radeon桌面版 / 移动版等）和侧重计算及企业市场的CDNA（适用在INSTINCT系列上）双路线。&lt;a href=&#34;https://www.tomshardware.com/pc-components/cpus/amd-announces-unified-udna-gpu-architecture-bringing-rdna-and-cdna-together-to-take-on-nvidias-cuda-ecosystem&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;9月AMD宣布未来将整合RDNA和CDNA&lt;/a&gt;。这也是AMD在有限资源下的理性选择，而且长期来看，更集中、更统一的支持、降低的软硬件架构开销可以更有效的与对手竞争，但短期内整合两套架构的过程中仍可能会有不确定性，产品和技术支持和服务可能有连续性、兼容性的问题，毕竟这事在AMD上也不是第一次发生:dog:。&lt;/p&gt;&#xA;&lt;h2 id=&#34;曲线救国其他更开放的计算框架&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;“曲线救国”：其他更开放的计算框架&lt;/span&gt;&#xA;  &lt;a href=&#34;#%e6%9b%b2%e7%ba%bf%e6%95%91%e5%9b%bd%e5%85%b6%e4%bb%96%e6%9b%b4%e5%bc%80%e6%94%be%e7%9a%84%e8%ae%a1%e7%ae%97%e6%a1%86%e6%9e%b6&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;Nvidia挟千百万用户之众，又坐拥产业链之便、CUDA之标准，此诚不可与争锋也。那么其它的GPU厂商（如国内华为、海思、平头哥等），破局出路究竟在哪里？在这里我们仅就GPU生态来说，AMD无疑是打了一个样，本章节我们将视野放宽，来看看DirectML、Zluda、SCALE等一些开源/初创的GPU计算框架（GPGPU）他们是怎么做的，他们前行的方向也许能给我们一些启发和思路。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;DirectML&lt;/strong&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://github.com/microsoft/DirectML&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;DirectML&lt;/a&gt;是微软开发的一种GPGPU技术（或称之为接口），它也是面向底层的、低层次的机器学习/深度学习库，它的主要特色是：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;依赖于DirectX 12，但兼容不同的硬件，凡支持DirectX 12的GPU如AMD、Nvidia、Intel、甚至 高通（Qualcomm）都可以使用；&lt;/li&gt;&#xA;&lt;li&gt;面向windows环境；&lt;/li&gt;&#xA;&lt;li&gt;可以通过torch-directml包来使用pytorch，以实现上层模型训练、推理并启动GPU支持；&lt;/li&gt;&#xA;&lt;li&gt;对一些基础的运算做了封装和支持，&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;DirectML可以视为许多GPU厂商的盟友，如对AMD用户的意义包括：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;支持windows系统上的AI训练与开发，特别是AMD自身在window上久久没有很好的支持情况下；&lt;/li&gt;&#xA;&lt;li&gt;对老版本的显卡有较好的支持。&#xA;但毕竟Window环境很难成为练丹的第一选择，另外，DirectML相较于原生的接口效率上也会更低一些。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;ZLUDA&lt;/strong&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://github.com/vosen/ZLUDA&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;ZLUDA&lt;/a&gt;是另一个令人印象深刻的开源GPGPU项目，它的最大特色在于直接锚定CUDA，力图实现在非Nvidia的GPU上可直接运行CUDA代码，并尽可能提高运行效率。 ZLUDA的逻辑疑似是在GPU上添加了一个模拟层或转译层，以解释并兼容CUDA，从而实现跨平台的执行，这个思路和国内一众的GPU生产厂商一致。&lt;/p&gt;&#xA;&lt;p&gt;ZLUDA最初是个人作品，后来成为社区开源的共同项目。根据用户反馈，ZLUDA显示出了不错的性能，早前ZLUDA表现甚至能够超越ROCm，并对windows系统、老型号的显卡有着较好的支持。&lt;/p&gt;&#xA;&lt;p&gt;ZLUDA曾经得到AMD和Intel的支持。但随着Nvidia对CUDA的限制越来越严格（CUDA为闭源），如&lt;a href=&#34;https://www.tomshardware.com/pc-components/gpus/nvidia-bans-using-translation-layers-for-cuda-software-to-run-on-other-chips-new-restriction-apparently-targets-zluda-and-some-chinese-gpu-makers&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;明确禁止通过模拟层运行CUDA&lt;/a&gt;，并限制任何的逆向工程、反编译等，Intel和AMD都停止了对它的资助。&lt;/p&gt;&#xA;&lt;p&gt;好消息是，10月初创始人在&lt;a href=&#34;https://vosen.github.io/ZLUDA/blog/zludas-third-life/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;博客中宣称&lt;/a&gt;，ZLUDA获得了一位不具名厂商的投资，可以继续开发这一项目，但同时，考虑到法律风险、技术风险，ZLUDA自身也会做出不少的调整：a. 代码重构；b. 重心上会聚焦到机器学习、大模型上；c. 也将与AMD/Intel各自的GPGPU差异化，如强化HIP做得不好的图片相关的计算、更多支持一些尚未被支持的AMD GPU等。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;SCALE&lt;/strong&gt;&lt;br&gt;&#xA;另一个值得关注的新起之秀是SCALE，根据&lt;a href=&#34;https://docs.scale-lang.com/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;介绍文档&lt;/a&gt;，它是一种能够支持CUDA编写的程序原生的运行在AMD GPU上，而无需任何的转译层，换言之，它并不依赖 CUDA本身，而是&lt;a href=&#34;https://docs.scale-lang.com/manual/how-to-use/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;本身模拟CUDA的功能和角色&lt;/a&gt;。当前看来，&lt;a href=&#34;https://docs.scale-lang.com/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;SCALE所能够支持的算法和算子还相对有限&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;br&gt;&#xA;勇者半恶龙总是一个大众喜闻乐见的故事。对ZLUDA项目我深表敬意，SCALE项目也值得关注，这二者某种程序上也可作为我国GPU生态开发的学习参照。综合以上信息年来，AMD走的是一条全面对标CUDA、全生态自研的发展路径；SCALE是保持CUDA语法、接口不变的情况下，确保全面兼容CUDA语言和生态内的其它工具；ZLUDA则是更接近对CUDA的转译，仍借助于CUDA本身。前者更适合作为硬件厂商长期的发展路线，后者则适合中短期内较快速的面向市场推广自家的产品，并确保用户以低成本学习和应用。&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;&lt;/th&gt;&#xA;          &lt;th&gt;HIP&lt;/th&gt;&#xA;          &lt;th&gt;ZLUDA&lt;/th&gt;&#xA;          &lt;th&gt;SCALE&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;生产方&lt;/td&gt;&#xA;          &lt;td&gt;AMD&lt;/td&gt;&#xA;          &lt;td&gt;个人与社区&lt;/td&gt;&#xA;          &lt;td&gt;初创公司 Spectral Compute&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;是否开源&lt;/td&gt;&#xA;          &lt;td&gt;是&lt;/td&gt;&#xA;          &lt;td&gt;是&lt;/td&gt;&#xA;          &lt;td&gt;否（开发测试中）&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;是否兼容CUDA&lt;/td&gt;&#xA;          &lt;td&gt;- 大部分&lt;br&gt; - 以功能对齐为准，部分命令和语句不同于CUDA&lt;/td&gt;&#xA;          &lt;td&gt;- 是&lt;br&gt; - 全面兼容CUDA&lt;/td&gt;&#xA;          &lt;td&gt;- 绝大部分&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;技术路线&lt;/td&gt;&#xA;          &lt;td&gt;a. 对照CUDA 接口开发并对齐功能；&lt;br&gt;b. 支持和调用ROCm 生态圈工具&lt;/td&gt;&#xA;          &lt;td&gt;扮演转译层，从而将CUDA 程序运行在非 Nvidia GPU 上（类似于逆向工程）&lt;/td&gt;&#xA;          &lt;td&gt;a. 完全沿袭CUDA 的指令和接口模式；&lt;br&gt;b. 独立构建和实现CUDA 的功能&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;其它&lt;/td&gt;&#xA;          &lt;td&gt;同时兼容OpenCL&lt;br&gt;可基于HIP 开发扩展新功能&lt;/td&gt;&#xA;          &lt;td&gt;有老版本GPU、多系统支持&lt;/td&gt;&#xA;          &lt;td&gt;仍以兼容CUDA 相关工具为主，不包括ROCm 生态圈的其它工具&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;评论&lt;/td&gt;&#xA;          &lt;td&gt;a. 开发成本高，自主性强；&lt;br&gt;b. 与CUDA 仍会有一定程度的适配问题，带来的用户使用成本较高；&lt;br&gt;c. 保持对CUDA 的跟进和对照开发，成本高。&lt;/td&gt;&#xA;          &lt;td&gt;a. 开发成本相对较低；&lt;br&gt;b. 强依赖于CUDA 及相关工具， 自主性较弱，有一定的合规风险；&lt;br&gt;c. CUDA 支持度高，无需要额外的调整和适配&lt;/td&gt;&#xA;          &lt;td&gt;a. 开发成本相对较高；&lt;br&gt;b. 全面兼容但不依赖于CUDA ， 自主性较强，有一定的合规风险；&lt;br&gt;c. 可视为AMD 上的CUDA&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;用户视角&lt;/td&gt;&#xA;          &lt;td&gt;大量资源迁移到AMD GPU 上；有较强的代码研发能力&lt;/td&gt;&#xA;          &lt;td&gt;低成本快速切换到AMD GPU；对个人用户友好&lt;/td&gt;&#xA;          &lt;td&gt;由于当前支持的算法和算子较少，建议进一步观望&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;GPU厂商视角&lt;/td&gt;&#xA;          &lt;td&gt;- 独立自研，更能配合公司的长期战略；&lt;br&gt; - 适用于服务技术能力强的大客户&lt;/td&gt;&#xA;          &lt;td&gt;- 适合搭配GPU应用推广，或在中短期探索阶段；&lt;br&gt; - 有合规风险&lt;/td&gt;&#xA;          &lt;td&gt;中间选择，可以先将核心的CUDA 能力移植到GPU 上，再扩展其它能力与工具&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;参考资料&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;参考资料&lt;/span&gt;&#xA;  &lt;a href=&#34;#%e5%8f%82%e8%80%83%e8%b5%84%e6%96%99&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;ul&gt;&#xA;&lt;li&gt;ROCm Developer Hub: &lt;a href=&#34;https://www.amd.com/en/developer/resources/rocm-hub.html&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://www.amd.com/en/developer/resources/rocm-hub.html&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;ZLUDA: &lt;a href=&#34;https://github.com/vosen/ZLUDA&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/vosen/ZLUDA&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;DirectML：https://learn.microsoft.com/zh-cn/windows/ai/directml/dml&lt;/li&gt;&#xA;&lt;li&gt;SCALE: &lt;a href=&#34;https://docs.scale-lang.com/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://docs.scale-lang.com/&lt;/a&gt; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/678371087&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://zhuanlan.zhihu.com/p/678371087&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;AMD GPU硬件架构：https://fpga.eetrend.com/content/2024/100577289.html &lt;a href=&#34;https://zhuanlan.zhihu.com/p/651026452&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://zhuanlan.zhihu.com/p/651026452&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;AMD GPU介绍： &lt;a href=&#34;https://zhuanlan.zhihu.com/p/545296023&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://zhuanlan.zhihu.com/p/545296023&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;关于CUDA的介绍也可参见: &lt;a href=&#34;https://zhuanlan.zhihu.com/p/668749361&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://zhuanlan.zhihu.com/p/668749361&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;知乎关于CUDA ROCm的讨论：https://www.zhihu.com/question/564812763 或 &lt;a href=&#34;https://www.zhihu.com/question/618150944&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://www.zhihu.com/question/618150944&lt;/a&gt;；在reddit上的讨论有 &lt;a href=&#34;https://www.reddit.com/r/MachineLearning/comments/1fa8vq5/d_why_is_cuda_so_much_faster_than_rocm/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://www.reddit.com/r/MachineLearning/comments/1fa8vq5/d_why_is_cuda_so_much_faster_than_rocm/&lt;/a&gt; 及 &lt;a href=&#34;https://www.reddit.com/r/Amd/comments/1bxlp3r/how_good_are_amd_gpus_at_running_large_language/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://www.reddit.com/r/Amd/comments/1bxlp3r/how_good_are_amd_gpus_at_running_large_language/&lt;/a&gt;，其中不乏洞见。&lt;/li&gt;&#xA;&lt;li&gt;关于GPGPU的讨论：https://www.zhihu.com/question/461354739/answer/3259844830&lt;/li&gt;&#xA;&lt;li&gt;AMD GPU评测与配置：https://llm-tracker.info/howto/AMD-GPUs &lt;a href=&#34;https://github.com/nktice/AMD-AI&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/nktice/AMD-AI&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
